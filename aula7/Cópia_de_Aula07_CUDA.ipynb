{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAqxUIh9E1Fa"
      },
      "source": [
        "## Programando em CUDA - Aula 07"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comandos básicos"
      ],
      "metadata": {
        "id": "FrcxQSVSap8t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Código para a execução de programas CUDA no ambiente Colab"
      ],
      "metadata": {
        "id": "EeyAKeQialxU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nvcc4jupyter"
      ],
      "metadata": {
        "id": "YDNPM7dRRmjc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0eb89551-9c87-44c4-c177-0a5576c87df7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvcc4jupyter\n",
            "  Downloading nvcc4jupyter-1.2.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Downloading nvcc4jupyter-1.2.1-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc4jupyter"
      ],
      "metadata": {
        "id": "PQeuP-0jRr0P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "472cc4b6-78ce-4e34-e507-23124016c8fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected platform \"Colab\". Running its setup...\n",
            "Source files will be saved in \"/tmp/tmpyjb09l2r\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0TzyOF5FBAY"
      },
      "source": [
        "Descobrindo qual GPU foi alocada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDSC73nEE9VI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9d7dc28-55bc-41d5-8945-2c789398552e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Apr  2 14:04:50 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   65C    P8             12W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlAdHNF-FDUL"
      },
      "source": [
        "Verificando a versão do nvcc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4VCnCqPwEsug",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a93bec30-dc66-4d38-a3d4-e1d06baf2d5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEl-M6V8FIys"
      },
      "source": [
        "# Identificadores locais e globais de threads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tj1czWdLFG9i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5310680a-d177-403a-854a-0657afa46a4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void loop()\n",
        "{\n",
        "  /*\n",
        "   * This idiomatic expression gives each thread\n",
        "   * a unique index within the entire grid.\n",
        "   */\n",
        "\n",
        "  int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  printf(\"%d\\n\", i);\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "  /*\n",
        "   * Additional execution configurations that would\n",
        "   * work and meet the exercises contraints are:\n",
        "   *\n",
        "   */\n",
        "\n",
        "  loop<<<10, 3>>>();\n",
        "  cudaDeviceSynchronize();\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Impressão de algumas características da placa de vídeo"
      ],
      "metadata": {
        "id": "PVctwEMLaWKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "\n",
        "\n",
        "// Print device properties\n",
        "void printDevProp(cudaDeviceProp devProp)\n",
        "{\n",
        "    printf(\"Major revision number:         %d\\n\",  devProp.major);\n",
        "    printf(\"Minor revision number:         %d\\n\",  devProp.minor);\n",
        "    printf(\"Name:                          %s\\n\",  devProp.name);\n",
        "    printf(\"Total global memory:           %lu\\n\",  devProp.totalGlobalMem);\n",
        "    printf(\"Total shared memory per block: %lu\\n\",  devProp.sharedMemPerBlock);\n",
        "    printf(\"Total registers per block:     %d\\n\",  devProp.regsPerBlock);\n",
        "    printf(\"Warp size:                     %d\\n\",  devProp.warpSize);\n",
        "    printf(\"Maximum memory pitch:          %lu\\n\",  devProp.memPitch);\n",
        "    printf(\"Maximum threads per block:     %d\\n\",  devProp.maxThreadsPerBlock);\n",
        "    for (int i = 0; i < 3; ++i)\n",
        "        printf(\"Maximum dimension %d of block:  %d\\n\", i, devProp.maxThreadsDim[i]);\n",
        "    for (int i = 0; i < 3; ++i)\n",
        "        printf(\"Maximum dimension %d of grid:   %d\\n\", i, devProp.maxGridSize[i]);\n",
        "    printf(\"Clock rate:                    %d\\n\",  devProp.clockRate);\n",
        "    printf(\"Total constant memory:         %lu\\n\",  devProp.totalConstMem);\n",
        "    printf(\"Texture alignment:             %lu\\n\",  devProp.textureAlignment);\n",
        "    printf(\"Concurrent copy and execution: %s\\n\",  (devProp.deviceOverlap ? \"Yes\" : \"No\"));\n",
        "    printf(\"Number of multiprocessors:     %d\\n\",  devProp.multiProcessorCount);\n",
        "    printf(\"Kernel execution timeout:      %s\\n\",  (devProp.kernelExecTimeoutEnabled ?\"Yes\" : \"No\"));\n",
        "    return;\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    int devCount;\n",
        "    cudaGetDeviceCount(&devCount);\n",
        "    printf(\"CUDA Device Query...\\n\");\n",
        "    printf(\"There are %d CUDA devices.\\n\", devCount);\n",
        "\n",
        "    for (int i = 0; i < devCount; ++i)\n",
        "    {\n",
        "        // Get device properties\n",
        "        printf(\"\\nCUDA Device #%d\\n\", i);\n",
        "        cudaDeviceProp devProp;\n",
        "        cudaGetDeviceProperties(&devProp, i);\n",
        "        printDevProp(devProp);\n",
        "    }\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "-q4xmRygvhKq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "576b6726-31d2-4287-ec21-36b3ef514ae3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA Device Query...\n",
            "There are 1 CUDA devices.\n",
            "\n",
            "CUDA Device #0\n",
            "Major revision number:         7\n",
            "Minor revision number:         5\n",
            "Name:                          Tesla T4\n",
            "Total global memory:           15828320256\n",
            "Total shared memory per block: 49152\n",
            "Total registers per block:     65536\n",
            "Warp size:                     32\n",
            "Maximum memory pitch:          2147483647\n",
            "Maximum threads per block:     1024\n",
            "Maximum dimension 0 of block:  1024\n",
            "Maximum dimension 1 of block:  1024\n",
            "Maximum dimension 2 of block:  64\n",
            "Maximum dimension 0 of grid:   2147483647\n",
            "Maximum dimension 1 of grid:   65535\n",
            "Maximum dimension 2 of grid:   65535\n",
            "Clock rate:                    1590000\n",
            "Total constant memory:         65536\n",
            "Texture alignment:             512\n",
            "Concurrent copy and execution: Yes\n",
            "Number of multiprocessors:     40\n",
            "Kernel execution timeout:      No\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Questão 1"
      ],
      "metadata": {
        "id": "S4QJximBb0Ab"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Crie um código que imprima os valores pares de 0 até 20 utilizando programação CUDA"
      ],
      "metadata": {
        "id": "dq3ITRNTb3Zf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void num_pares(){\n",
        "    int idx = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    if (idx%2==0){\n",
        "      printf(\"%d \\n\",idx);\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(){\n",
        "\n",
        "    num_pares<<<2,10>>>();\n",
        "    cudaDeviceSynchronize();\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "gENximqD4PT6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64cd960c-bb50-4c42-dffc-86a9b68c345e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evitando acessos fora da faixa do vetor"
      ],
      "metadata": {
        "id": "CsbRPdzAyLZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "\n",
        "\n",
        "__global__ void initializeElementsTo(int initialValue, int *a, int N)\n",
        "{\n",
        "  int i = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "  if (i < N)\n",
        "  {\n",
        "    a[i] = initialValue;\n",
        "  }\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "  /*\n",
        "   * Do not modify `N`.\n",
        "   */\n",
        "\n",
        "  int N = 1000;\n",
        "\n",
        "  int *a;\n",
        "  size_t size = N * sizeof(int);\n",
        "\n",
        "  cudaMallocManaged(&a, size);\n",
        "\n",
        "  /*\n",
        "   * Assume we have reason to want the number of threads\n",
        "   * fixed at `256`: do not modify `threads_per_block`.\n",
        "   */\n",
        "\n",
        "  size_t threads_per_block = 256;\n",
        "\n",
        "  /*\n",
        "   * The following is idiomatic CUDA to make sure there are at\n",
        "   * least as many threads in the grid as there are `N` elements.\n",
        "   */\n",
        "\n",
        "  size_t number_of_blocks = 4;\n",
        "  //size_t number_of_blocks = (N + threads_per_block - 1) / threads_per_block;\n",
        "\n",
        "  int initialValue = 6;\n",
        "\n",
        "  initializeElementsTo<<<number_of_blocks, threads_per_block>>>(initialValue, a, N);\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  /*\n",
        "   * Check to make sure all values in `a`, were initialized.\n",
        "   */\n",
        "\n",
        "  for (int i = 0; i < N; ++i)\n",
        "  {\n",
        "    if(a[i] != initialValue)\n",
        "    {\n",
        "      printf(\"FAILURE: target value: %d\\t a[%d]: %d\\n\", initialValue, i, a[i]);\n",
        "      cudaFree(a);\n",
        "      exit(1);\n",
        "    }\n",
        "  }\n",
        "  printf(\"SUCCESS!\\n\");\n",
        "\n",
        "  cudaFree(a);\n",
        "}"
      ],
      "metadata": {
        "id": "eQb2pp45yOzn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5346fc94-6565-477e-8a3c-354aef88aba3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAILURE: target value: 6\t a[0]: 0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lidando com mais dados do que threads: strides (passadas)"
      ],
      "metadata": {
        "id": "xEFSYy3Qyawa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#Código removido\n"
      ],
      "metadata": {
        "id": "pCtUhNqsygJW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4efa5066-5f2a-4d6e-f779-c792108a06c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All elements were doubled? TRUE\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exemplo utilizando %%writefile e compilando o arquivo"
      ],
      "metadata": {
        "id": "DCndPP62zrst"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile exemplo.cu\n",
        "\n",
        "#Código removido"
      ],
      "metadata": {
        "id": "ryDPFM_czsIe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66c4f5e1-a2ce-47d1-dcf8-a36080603690"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing exemplo.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o exemplo exemplo.cu"
      ],
      "metadata": {
        "id": "19SzpLaEzv62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./exemplo"
      ],
      "metadata": {
        "id": "3Jxthn7_1wTe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a539fc7f-2e2c-455e-d870-f6a3c7aef6e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All elements were doubled? TRUE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Questão 2"
      ],
      "metadata": {
        "id": "_eqvcuKx2vQC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Considerando os exemplos acima, crie um vetor de 100 posições e inicialize-o de forma parelela com valor 100. Em seguida, incremente-o em ordem crescente (de 0 à 99) em cada posição do vetor (da posição 0 à 99). Confira se seu resultado está correto."
      ],
      "metadata": {
        "id": "K4IBjvXs4X3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "//\n",
        "__global__ void initializeVector(int *vec, int size, int value) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < size) {\n",
        "        vec[idx] = value;\n",
        "    }\n",
        "}\n",
        "\n",
        "// Kernel para incrementar cada elemento com seu índice\n",
        "__global__ void incrementWithIndex(int *vec, int size) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < size) {\n",
        "        vec[idx] += idx;\n",
        "    }\n",
        "}\n",
        "\n",
        "// Função para verificar o resultado\n",
        "bool checkResult(int *vec, int size) {\n",
        "    for (int i = 0; i < size; i++) {\n",
        "        if (vec[i] != (100 + i)) {\n",
        "            printf(\"Erro na posição %d: esperado %d, encontrado %d\\n\",\n",
        "                   i, 100 + i, vec[i]);\n",
        "            return false;\n",
        "        }\n",
        "    }\n",
        "    return true;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    const int N = 100;\n",
        "    int *vec;\n",
        "    size_t size = N * sizeof(int);\n",
        "\n",
        "    // Alocar memória gerenciada\n",
        "    cudaMallocManaged(&vec, size);\n",
        "\n",
        "    // Configurar a execução dos kernels\n",
        "    int threadsPerBlock = 32;\n",
        "    int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;\n",
        "\n",
        "    // Inicializar o vetor com 100\n",
        "    initializeVector<<<blocksPerGrid, threadsPerBlock>>>(vec, N, 100);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Incrementar cada posição com seu índice\n",
        "    incrementWithIndex<<<blocksPerGrid, threadsPerBlock>>>(vec, N);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Verificar o resultado\n",
        "    if (checkResult(vec, N)) {\n",
        "        printf(\"Resultado correto! Todos os elementos foram processados adequadamente.\\n\");\n",
        "\n",
        "        // Opcional: imprimir os primeiros e últimos elementos para verificação\n",
        "        printf(\"Primeiros 5 elementos: \");\n",
        "        for (int i = 0; i < 5; i++) printf(\"%d \", vec[i]);\n",
        "        printf(\"\\nÚltimos 5 elementos: \");\n",
        "        for (int i = N-5; i < N; i++) printf(\"%d \", vec[i]);\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "    // Liberar memória\n",
        "    cudaFree(vec);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "MSQ4X66z4Lkf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66301fed-7d62-4d77-9557-641aa04d1beb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Erro na posição 0: esperado 100, encontrado 0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Questão 3"
      ],
      "metadata": {
        "id": "aF5DY03I3jXl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Considerando os exemplos acima, crie dois vetores de 1000 posições e inicialize o primeiro vetor de forma parelela com valor decrescente (de 0 à 999) e o segundo vetor com valores crescentes (de 0 à 99). Em seguida, faça a soma dos dois vetores, elemento a elemento. Crie uma função sequencial para retornar se todos os valores do vetor resultante são iguais."
      ],
      "metadata": {
        "id": "nW7skxld4U9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Código da questão 3"
      ],
      "metadata": {
        "id": "mDGi7DNK4H2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Programa para somar dois vetores"
      ],
      "metadata": {
        "id": "0_aA-0eREiUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile teste.cu\n",
        "#Código removido"
      ],
      "metadata": {
        "id": "MP-e9985EmRM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50b42de5-ee78-4feb-a035-415e32631c69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing teste.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o teste teste.cu -run"
      ],
      "metadata": {
        "id": "BQXq_Zj2FEIb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4287c38c-b908-424a-c6e4-3ceb3395f553"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success! All values calculated correctly.\n",
            "Success! All values calculated correctly.\n",
            "Success! All values calculated correctly.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof ./teste"
      ],
      "metadata": {
        "id": "gxhFtCcyFF33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d4982ad-6891-43ec-c8b9-15c7de8ed127"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==7372== NVPROF is profiling process 7372, command: ./teste\n",
            "Success! All values calculated correctly.\n",
            "Success! All values calculated correctly.\n",
            "Success! All values calculated correctly.\n",
            "==7372== Profiling application: ./teste\n",
            "==7372== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:  100.00%  3.85746s         2  1.92873s  1.81797s  2.03949s  addVectorsInto(float*, float*, float*, int)\n",
            "      API calls:   96.89%  3.85747s         1  3.85747s  3.85747s  3.85747s  cudaDeviceSynchronize\n",
            "                    2.57%  102.34ms         3  34.112ms  25.675us  102.24ms  cudaMallocManaged\n",
            "                    0.53%  20.951ms         3  6.9836ms  6.9513ms  7.0338ms  cudaFree\n",
            "                    0.01%  322.73us         2  161.36us  7.5560us  315.17us  cudaLaunchKernel\n",
            "                    0.00%  148.76us       114  1.3040us     137ns  55.222us  cuDeviceGetAttribute\n",
            "                    0.00%  29.455us         1  29.455us  29.455us  29.455us  cuDeviceGetName\n",
            "                    0.00%  6.3670us         1  6.3670us  6.3670us  6.3670us  cuDeviceTotalMem\n",
            "                    0.00%  5.6700us         1  5.6700us  5.6700us  5.6700us  cuDeviceGetPCIBusId\n",
            "                    0.00%  1.5350us         3     511ns     190ns  1.1060us  cuDeviceGetCount\n",
            "                    0.00%  1.2240us         2     612ns     204ns  1.0200us  cuDeviceGet\n",
            "                    0.00%  1.0360us         1  1.0360us  1.0360us  1.0360us  cudaGetLastError\n",
            "                    0.00%     525ns         1     525ns     525ns     525ns  cuModuleGetLoadingMode\n",
            "                    0.00%     257ns         1     257ns     257ns     257ns  cuDeviceGetUuid\n",
            "\n",
            "==7372== Unified Memory profiling result:\n",
            "Device \"Tesla T4 (0)\"\n",
            "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
            "    2304  170.67KB  4.0000KB  0.9961MB  384.0000MB  38.63193ms  Host To Device\n",
            "    2304  170.67KB  4.0000KB  0.9961MB  384.0000MB  33.74300ms  Device To Host\n",
            "     768         -         -         -           -  136.7858ms  Gpu page fault groups\n",
            "Total CPU Page faults: 2304\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Questão 4\n"
      ],
      "metadata": {
        "id": "GLFVOeYRFqYl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implemente um código para inicializar dois vetores de tamanho N ($N=70$). O primeiro vetor deve ser inicializado com valor igual a 10 e o segundo vetor deve ser inicializado com valor crescente (de 0 a $N-1$). Imprima a multiplicação do primeiro vetor com o segundo vetor, elemento a elemento. Obs.: Considere o bloco com 32 threads."
      ],
      "metadata": {
        "id": "I6CPTr2tF3l8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "// Kernel para inicializar o vetor com valor constante\n",
        "__global__ void initializeConstant(int *vec, int size, int value) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < size) {\n",
        "        vec[idx] = value;\n",
        "    }\n",
        "}\n",
        "\n",
        "// Kernel para inicializar o vetor com valores crescentes\n",
        "__global__ void initializeIncremental(int *vec, int size) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < size) {\n",
        "        vec[idx] = idx;\n",
        "    }\n",
        "}\n",
        "\n",
        "// Kernel para multiplicar os vetores elemento a elemento\n",
        "__global__ void multiplyVectors(int *vecA, int *vecB, int *result, int size) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < size) {\n",
        "        result[idx] = vecA[idx] * vecB[idx];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    const int N = 70;\n",
        "    int *vecA, *vecB, *result;\n",
        "    size_t size = N * sizeof(int);\n",
        "\n",
        "    // Alocar memória gerenciada para os vetores\n",
        "    cudaMallocManaged(&vecA, size);\n",
        "    cudaMallocManaged(&vecB, size);\n",
        "    cudaMallocManaged(&result, size);\n",
        "\n",
        "    // Configurar a execução dos kernels (32 threads por bloco)\n",
        "    int threadsPerBlock = 32;\n",
        "    int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;\n",
        "\n",
        "    // Inicializar os vetores\n",
        "    initializeConstant<<<blocksPerGrid, threadsPerBlock>>>(vecA, N, 10);\n",
        "    initializeIncremental<<<blocksPerGrid, threadsPerBlock>>>(vecB, N);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Multiplicar os vetores\n",
        "    multiplyVectors<<<blocksPerGrid, threadsPerBlock>>>(vecA, vecB, result, N);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Imprimir os resultados\n",
        "    printf(\"Multiplicação dos vetores (elemento a elemento):\\n\");\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        printf(\"%d * %d = %d\\n\", vecA[i], vecB[i], result[i]);\n",
        "    }\n",
        "\n",
        "    // Liberar memória\n",
        "    cudaFree(vecA);\n",
        "    cudaFree(vecB);\n",
        "    cudaFree(result);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "tSC690eEF4DZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09b5244e-8b52-4e3b-86cd-2592c51b94fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multiplicação dos vetores (elemento a elemento):\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "0 * 0 = 0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Questão 5"
      ],
      "metadata": {
        "id": "SRq7TPk5Fus5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implemente um código para inicializar um vetor com 1000 posições com valores entre 0 a 999. Eleve todos os valores ao quadrado ($x^2$). Retorne se as operações foram realizadas com sucesso ou se houve falha. Obs.: número de blocos = 32 e número de threads igual a 256 por bloco."
      ],
      "metadata": {
        "id": "sIo23bAuFz6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "// Kernel para inicialização do vetor com valores de 0 a 999\n",
        "__global__ void initializeVector(int *vec, int size) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < size) {\n",
        "        vec[idx] = idx;\n",
        "    }\n",
        "}\n",
        "\n",
        "// Kernel para elevar os elementos ao quadrado\n",
        "__global__ void squareVector(int *vec, int size) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < size) {\n",
        "        vec[idx] = vec[idx] * vec[idx];\n",
        "    }\n",
        "}\n",
        "\n",
        "// Função de verificação\n",
        "bool verifyResults(int *vec, int size) {\n",
        "    for (int i = 0; i < size; i++) {\n",
        "        if (vec[i] != i * i) {\n",
        "            printf(\"Erro na posição %d: Esperado %d, Obtido %d\\n\", i, i*i, vec[i]);\n",
        "            return false;\n",
        "        }\n",
        "    }\n",
        "    return true;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    const int N = 1000;\n",
        "    int *vec;\n",
        "    size_t size = N * sizeof(int);\n",
        "    cudaError_t err;\n",
        "\n",
        "    // Alocar memória gerenciada\n",
        "    err = cudaMallocManaged(&vec, size);\n",
        "    if (err != cudaSuccess) {\n",
        "        printf(\"Erro na alocação: %s\\n\", cudaGetErrorString(err));\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    // Configuração da execução\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocksPerGrid = 32;\n",
        "\n",
        "    // Inicializar vetor\n",
        "    initializeVector<<<blocksPerGrid, threadsPerBlock>>>(vec, N);\n",
        "    err = cudaDeviceSynchronize();\n",
        "    if (err != cudaSuccess) {\n",
        "        printf(\"Erro na inicialização: %s\\n\", cudaGetErrorString(err));\n",
        "        cudaFree(vec);\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    // Elevar ao quadrado\n",
        "    squareVector<<<blocksPerGrid, threadsPerBlock>>>(vec, N);\n",
        "    err = cudaDeviceSynchronize();\n",
        "    if (err != cudaSuccess) {\n",
        "        printf(\"Erro na operação de quadrado: %s\\n\", cudaGetErrorString(err));\n",
        "        cudaFree(vec);\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    // Verificar resultados\n",
        "    if (verifyResults(vec, N)) {\n",
        "        printf(\"Sucesso! Todos os elementos foram processados corretamente.\\n\");\n",
        "    } else {\n",
        "        printf(\"Falha! Erros encontrados nos resultados.\\n\");\n",
        "    }\n",
        "\n",
        "    // Liberar memória\n",
        "    cudaFree(vec);\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "_PRVY46BF6S9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc46ae8c-74cc-4574-94f8-c67c59e2af4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Erro na posição 1: Esperado 1, Obtido 0\n",
            "Falha! Erros encontrados nos resultados.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Questão 6"
      ],
      "metadata": {
        "id": "BTUrAXztFyWd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Proponha uma solução paralela em CUDA para o cálculo da seguinte expressão vetorial: $V=k_1*A+k_2*B$, onde $k_1$ e $k_2$ são constantes e $A$ e $B$ são vetores de tamanho $n=500$. Utilize $n_{blocos}=8$ e $n_{threads}=16$. Inicialize os vetores $A$ e $B$ de forma paralela e com valores arbitrários (definidos pelo programador). Imprima o vetor $V$."
      ],
      "metadata": {
        "id": "qplrP069F1SG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Insira seu código aqui"
      ],
      "metadata": {
        "id": "yg4dX1kRF7Ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Questão 7"
      ],
      "metadata": {
        "id": "nXUSOcJ7HE1h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implemente um código para inicializar dois vetores de tamanho N ($N=1000$). O primeiro vetor deve ser inicializado com valor crescente (de 0 a $N-1$) e o segundo vetor deve ser inicializado com valor decrescente (de $N-1$ a 0). Realize a soma do primeiro vetor com o segundo vetor, elemento a elemento, e insira em um terceiro vetor. Verifique se todos os valores são iguais, caso positivo, imprima “Sucesso! Todos os valores sao identicos”, senão, imprima “Erro detectado no codigo”. Obs.:  número de blocos = 8 e número de threads igual a 16 por bloco."
      ],
      "metadata": {
        "id": "3InD5REYHGOZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Insira seu código aqui\n",
        "\n",
        "#Utilize a seguinte função de verificação\n",
        "void verificacao(int *c, int N)\n",
        "{\n",
        "  for(int i = 0; i < N; i++)\n",
        "  {\n",
        "    if(c[i] != c[0])\n",
        "    {\n",
        "      printf(\"Erro detectado no codigo.\\n\");\n",
        "      exit(1);\n",
        "    }\n",
        "  }\n",
        "  printf(\"Sucesso! Todos os valores sao identicos.\\n\");\n",
        "}\n"
      ],
      "metadata": {
        "id": "YjfJV3RQHLfR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}