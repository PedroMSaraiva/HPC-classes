# ğŸ”¬ Sistema de SeleÃ§Ã£o de InstÃ¢ncias com Algoritmo GenÃ©tico e Random Forest

&#x20;  &#x20;

Este projeto expande o sistema modular original de anÃ¡lise com Random Forest ao incluir **seleÃ§Ã£o de instÃ¢ncias** com **Algoritmo GenÃ©tico (AG)** e **execuÃ§Ã£o paralela com Joblib**. O objetivo Ã© reduzir o nÃºmero de instÃ¢ncias nos datasets mantendo (ou atÃ© melhorando) a performance preditiva dos modelos.

---

## ğŸ§ Novas Funcionalidades

- SeleÃ§Ã£o de instÃ¢ncias com algoritmo genÃ©tico (AG tradicional)
- VersÃ£o paralela com **Joblib + Chunking**
- AvaliaÃ§Ã£o de desempenho com Random Forest e KNN
- MÃ©tricas de reduÃ§Ã£o de dados e acurÃ¡cia combinadas
- Processamento multiprocessado com aproveitamento total da CPU

---

## ğŸ“‚ Estrutura do Projeto

```
trabalho-final/
â”œâ”€â”€ run_instance_selection.py              # VersÃ£o com AG sequencial
â”œâ”€â”€ run_parallel_instance_selection.py     # VersÃ£o com AG paralelo (Joblib)
â”œâ”€â”€ rf_modules/
â”‚   â”œâ”€â”€ instance_selector.py               # SeleÃ§Ã£o de instÃ¢ncias com PyGAD
â”‚   â”œâ”€â”€ parallel_instance_selector.py      # SeleÃ§Ã£o paralela com Joblib
â”‚   â”œâ”€â”€ model.py                           # RandomForestModel e abstraÃ§Ã£o de treino
â”‚   â””â”€â”€ ...                                # Outros mÃ³dulos (data_loader, logger, etc.)
â”œâ”€â”€ docs                                   # DocumentaÃ§Ã£o
â”œâ”€â”€ dataset/                               # Datasets de entrada
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ instance_selection/                # Resultados do AG tradicional
â”‚   â”œâ”€â”€ parallel_instance_selection/       # Resultados da versÃ£o paralela
â”‚   â””â”€â”€ logs/                              # Arquivos de log e profiling
```

---

## âš™ï¸ Scripts DisponÃ­veis

### â–¶ï¸ `run_instance_selection.py`

Executa seleÃ§Ã£o de instÃ¢ncias com **PyGAD** para problemas de classificaÃ§Ã£o:

- Otimiza uma mÃ¡scara binÃ¡ria que define quais linhas do dataset manter
- Avalia fitness com Random Forest, equilibrando acurÃ¡cia e reduÃ§Ã£o de dados
- Salva os dados reduzidos em `results/instance_selection/`

---

### ğŸ¥µ `run_parallel_instance_selection.py`

Executa a versÃ£o **paralela** com **Joblib** e KNN para avaliaÃ§Ã£o mais leve:

- Divide a populaÃ§Ã£o de AG em chunks e avalia em paralelo
- Usa `KNeighborsClassifier` para acelerar fitness
- EstratÃ©gia robusta de fallback para subsets pequenos

---

### ğŸ§¬ `instance_selector.py`

MÃ³dulo com `InstanceSelector`, baseado em **PyGAD**, que:

- Treina modelos Random Forest a cada geraÃ§Ã£o
- Calcula fitness balanceando acurÃ¡cia e taxa de reduÃ§Ã£o
- Mostra progresso com `tqdm` e logs detalhados

---

### ğŸ§  `parallel_instance_selector.py`

MÃ³dulo com `ParallelInstanceSelector` que:

- Avalia chunks da populaÃ§Ã£o com `joblib.Parallel`
- Usa `KNN` com avaliaÃ§Ã£o rÃ¡pida para escalabilidade
- Aplica crossover e mutaÃ§Ã£o manuais a cada geraÃ§Ã£o

---

## ğŸ“Š MÃ©trica de Fitness

Ambos os mÃ©todos utilizam a seguinte fÃ³rmula:

```
fitness = (Î± Ã— acurÃ¡cia) + ((1 - Î±) Ã— taxa_reducao)
```

- Valor padrÃ£o de `Î± = 0.7`
- Penaliza soluÃ§Ãµes que mantÃªm muitas instÃ¢ncias
- Evita overfitting em subconjuntos muito pequenos

---

## ğŸš€ Como Executar

### Ambiente Conda

Crie e ative o ambiente com o arquivo `environment.yml` fornecido:

```bash
conda env create -f environment.yml
conda activate rf-env
```

### ExecuÃ§Ã£o

#### VersÃ£o GenÃ©tica Simples (PyGAD)

```bash
python run_instance_selection.py
```

#### VersÃ£o Paralela (Joblib + Chunking)

```bash
python run_parallel_instance_selection.py
```

---

## ğŸ’¾ Resultados

- Os datasets reduzidos serÃ£o salvos em `results/instance_selection/` ou `results/parallel_instance_selection/`
- Os arquivos CSV contÃªm apenas as instÃ¢ncias selecionadas com suas respectivas labels
- Logs completos de execuÃ§Ã£o estÃ£o disponÃ­veis no console e/ou `logs/`

---

## ğŸ§½ PrÃ³ximos Passos

- Suporte Ã  seleÃ§Ã£o de **atributos (features)** com algoritmos evolutivos
- IntegraÃ§Ã£o com interface HTML para visualizaÃ§Ã£o das soluÃ§Ãµes
- AvaliaÃ§Ã£o com mÃºltiplos modelos: SVM, XGBoost, LightGBM
- Multiobjetivo: acurÃ¡cia, reduÃ§Ã£o, tempo e generalizaÃ§Ã£o

---

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ licenciado sob a **LicenÃ§a MIT** â€“ consulte o arquivo `LICENSE`.

